{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Notebook for inserting time stamps not chronologically into a zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zarr\n",
    "import os\n",
    "from shutil import copyfile\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First greate an empty zarr, which will be build upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"test.zarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(datetime):\n",
    "    \"\"\"Create a spatial, single time step dataset with two variables.\"\"\"\n",
    "    dims = (\"time\", \"lat\", \"lon\")\n",
    "    time = [pd.to_datetime(datetime)]\n",
    "    w = 4000\n",
    "    h = 2000\n",
    "    lon = np.linspace(0, 4, w)\n",
    "    lat = np.linspace(50, 52, h)\n",
    "    precipitation_var = xr.DataArray(np.random.rand(1, h, w), coords=(time, lat, lon), dims=(\"time\", \"lat\", \"lon\"))\n",
    "    temperature_var = xr.DataArray(np.random.rand(1, h, w), coords=(time, lat, lon), dims=(\"time\", \"lat\", \"lon\"))\n",
    "    ds = xr.Dataset({\"precipitation\": precipitation_var, \"temperature\": temperature_var})\n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save a single time step dataset with default chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = create_dataset(\"2018-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (lat: 2000, lon: 4000, time: 1)\n",
       "Coordinates:\n",
       "  * time           (time) datetime64[ns] 2018-01-01\n",
       "  * lat            (lat) float64 50.0 50.0 50.0 50.0 ... 52.0 52.0 52.0 52.0\n",
       "  * lon            (lon) float64 0.0 0.001 0.002001 0.003001 ... 3.998 3.999 4.0\n",
       "Data variables:\n",
       "    precipitation  (time, lat, lon) float64 0.07173 0.6099 ... 0.3031 0.3511\n",
       "    temperature    (time, lat, lon) float64 0.965 0.9713 0.8693 ... 0.9365 0.136"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.time.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.precipitation.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.backends.zarr.ZarrStore at 0x7f798550e4a8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.to_zarr(DATASET_PATH, mode=\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect default chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (lat: 2000, lon: 4000, time: 1)\n",
       "Coordinates:\n",
       "  * lat            (lat) float64 50.0 50.0 50.0 50.0 ... 52.0 52.0 52.0 52.0\n",
       "  * lon            (lon) float64 0.0 0.001 0.002001 0.003001 ... 3.998 3.999 4.0\n",
       "  * time           (time) datetime64[ns] 2018-01-01\n",
       "Data variables:\n",
       "    precipitation  (time, lat, lon) float64 dask.array<shape=(1, 2000, 4000), chunksize=(1, 250, 500)>\n",
       "    temperature    (time, lat, lon) float64 dask.array<shape=(1, 2000, 4000), chunksize=(1, 250, 500)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunks': (1,),\n",
       " 'compressor': Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0),\n",
       " 'filters': None,\n",
       " 'units': 'days since 2018-01-01 00:00:00',\n",
       " 'calendar': 'proleptic_gregorian',\n",
       " 'dtype': dtype('int64')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.time.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunks': (1, 250, 500),\n",
       " 'compressor': Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0),\n",
       " 'filters': None,\n",
       " '_FillValue': nan,\n",
       " 'dtype': dtype('float64')}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.precipitation.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_group = zarr.open(\"test.zarr\", mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This zarr will only contain time stamps for every other day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3, 11, 2):\n",
    "    ds = create_dataset(f\"2018-01-0{i}\")\n",
    "    for var_name, var_array in root_group.arrays():\n",
    "        var = ds[var_name]\n",
    "        if 'time' in var.dims:            \n",
    "            time_axis = var.dims.index('time')\n",
    "            var_array.append(var, axis=time_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create another dataset which contains only one time stamp and will be appended to the first data set, stored in test.zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SINGLE_PATH = \"test_single.zarr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = create_dataset(\"2018-01-01\")\n",
    "ds.time.encoding\n",
    "ds.precipitation.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_zarr(DATASET_SINGLE_PATH, mode=\"w\")\n",
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_group = zarr.open(\"test_single.zarr\", mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = create_dataset(f\"2018-01-04\")\n",
    "for var_name, var_array in root_group.arrays():\n",
    "    var = ds[var_name]\n",
    "    if 'time' in var.dims:            \n",
    "        time_axis = var.dims.index('time')\n",
    "        var_array.append(var, axis=time_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr(DATASET_PATH, decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_single = xr.open_zarr(DATASET_SINGLE_PATH, decode_times=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (lat: 2000, lon: 4000, time: 5)\n",
       "Coordinates:\n",
       "  * lat            (lat) float64 50.0 50.0 50.0 50.0 ... 52.0 52.0 52.0 52.0\n",
       "  * lon            (lon) float64 0.0 0.001 0.002001 0.003001 ... 3.998 3.999 4.0\n",
       "  * time           (time) int64 0 1514937600000000000 ... 1515456000000000000\n",
       "Data variables:\n",
       "    precipitation  (time, lat, lon) float64 dask.array<shape=(5, 2000, 4000), chunksize=(1, 250, 500)>\n",
       "    temperature    (time, lat, lon) float64 dask.array<shape=(5, 2000, 4000), chunksize=(1, 250, 500)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:        (lat: 2000, lon: 4000, time: 2)\n",
       "Coordinates:\n",
       "  * lat            (lat) float64 50.0 50.0 50.0 50.0 ... 52.0 52.0 52.0 52.0\n",
       "  * lon            (lon) float64 0.0 0.001 0.002001 0.003001 ... 3.998 3.999 4.0\n",
       "  * time           (time) int64 0 1515024000000000000\n",
       "Data variables:\n",
       "    precipitation  (time, lat, lon) float64 dask.array<shape=(2, 2000, 4000), chunksize=(1, 250, 500)>\n",
       "    temperature    (time, lat, lon) float64 dask.array<shape=(2, 2000, 4000), chunksize=(1, 250, 500)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunks': (1,),\n",
       " 'compressor': Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0),\n",
       " 'filters': None,\n",
       " 'dtype': dtype('int64')}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.time.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunks': (1, 250, 500),\n",
       " 'compressor': Blosc(cname='lz4', clevel=5, shuffle=SHUFFLE, blocksize=0),\n",
       " 'filters': None,\n",
       " '_FillValue': nan,\n",
       " 'dtype': dtype('float64')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.precipitation.encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lat': 2000, 'lon': 4000, 'time': 5}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(ds.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([                  0, 1514937600000000000, 1515110400000000000,\n",
       "       1515283200000000000, 1515456000000000000])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([                  0, 1515024000000000000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_single.time.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()\n",
    "ds_single.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.time.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_single.time.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time stamp of both data sets is the same, in order to have the same time encoding. So in this case we are interested in the second time stamp of the ds_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.greater(ds.time.values, ds_single.time[1].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_single.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_above(array, target):\n",
    "    diff = array - target\n",
    "    mask = np.ma.less_equal(diff, 0)\n",
    "    # We need to mask the negative differences and zero\n",
    "    # since we are looking for values above\n",
    "    if np.all(mask):\n",
    "        return None # returns None if target is greater than any value\n",
    "    masked_diff = np.ma.masked_array(diff, mask)\n",
    "    return masked_diff.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_directory(path_to_ds, old_index, new_time_i):\n",
    "    ds = xr.open_zarr(path_to_ds, decode_times=False)\n",
    "    for v in ds.variables:\n",
    "        if (v != 'lat') and (v != 'lon'):\n",
    "            path = os.path.join(path_to_ds, v)\n",
    "            for root, dirs, files in os.walk(path):  \n",
    "                for filename in files:\n",
    "                    if (str(old_index)) in filename[0] and (v != \"time\"):\n",
    "                        parts = filename.split('.',1)\n",
    "                        new_name = (str(new_time_i) + '.{}').format(parts[1]) \n",
    "                        if new_name != path:\n",
    "                             os.rename(os.path.join(path, filename), os.path.join(path, new_name))\n",
    "                    elif (str(old_index)) in filename[0] and (v == \"time\"):\n",
    "                        if str(new_time_i) != path:\n",
    "                            os.rename(os.path.join(path, filename), os.path.join(path, str(new_time_i)))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_zarray(dst_path, variable, line_to_adjust):\n",
    "    with open((os.path.join(dst_path, variable, '.zarray')), 'r') as zarray:\n",
    "        data = zarray.readlines()\n",
    "    position = 8\n",
    "    white_space = 10\n",
    "    data[line_to_adjust] = (str(int(data[line_to_adjust][position])+1) + data[line_to_adjust][9:]).rjust(len(data[line_to_adjust][position])+white_space)\n",
    "\n",
    "    with open((os.path.join(dst_path, variable, '.zarray')), 'w') as zarray:\n",
    "        zarray.writelines(data)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_into_target(src_path, dst_path, src_index):\n",
    "    ds = xr.open_zarr(src_path, decode_times=False)\n",
    "    for v in ds.variables:\n",
    "        if (v != 'lat') and (v != 'lon'):\n",
    "            path = os.path.join(src_path, v)\n",
    "            for root, dirs, files in os.walk(path):  \n",
    "                for filename in files:\n",
    "                    if str(src_index) in filename[0]:\n",
    "                        copyfile((os.path.join(src_path, v, filename)), (os.path.join(dst_path, v,  filename)))\n",
    "                        if v != \"time\":\n",
    "                            line_to_adjust = 18\n",
    "                        elif v == \"time\":\n",
    "                            line_to_adjust = 16\n",
    "                        adjust_zarray(dst_path, v, line_to_adjust)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_single_zarr_into_destination_zarr(src_path, dst_path):\n",
    "    ds_single = xr.open_zarr(src_path, decode_times=False)\n",
    "    ds = xr.open_zarr(dst_path, decode_times=False)\n",
    "    new_idx = find_nearest_above(ds.time.values, ds_single.time[1].values)\n",
    "    old_idx = 1 # needs to be adjusted in order to be able to handle data sets with more than one timestamp\n",
    "# Preparing the source directory with the single time stamp to be ready for merging \n",
    "# --> files of variables, excluding \"lat\" and \"lon\" need to be renamed\n",
    "    rename_directory(src_path, old_idx, new_idx)\n",
    "# Preparing the destinanation directory to be ready for single time stam to be merged \n",
    "# --> files of variables, excluding \"lat\" and \"lon\" need to be renamed\n",
    "# The renaming needs to happen in reversed order and starting at the index of nearest above value:\n",
    "    for i in reversed(range(new_idx,ds.time.shape[0])):\n",
    "        rename_directory(dst_path, i, (i +1))\n",
    "# Final step: copy the single time stamp files into the destination zarr and adjusting .zarray to the change. \n",
    "    copy_into_target(src_path, dst_path, new_idx)\n",
    "# Remove the file containing the single time stamp:\n",
    "#     os.remove(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_single_zarr_into_destination_zarr(DATASET_SINGLE_PATH,DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open((os.path.join(DATASET_PATH, \"temperature\", '.zarray')), 'r') as zarray:\n",
    "          data = zarray.readlines()\n",
    "data[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(str(int(data[18][8])+1) + data[18][9:]).rjust(len(data[18][8])+10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data[16][len(data[line_to_adjust])-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[16])-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[18][9:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_to_adjust = 18\n",
    "position = 8\n",
    "white_space = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(str(int(data[line_to_adjust][position])+1) + data[line_to_adjust][9:]).rjust(len(data[line_to_adjust][position])+white_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
